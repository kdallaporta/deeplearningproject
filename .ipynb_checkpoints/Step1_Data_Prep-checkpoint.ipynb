{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff3d6d7-4b43-4fba-9d94-93906bbf0f52",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f1db6-3ad9-49c9-86e2-442562f7f11c",
   "metadata": {},
   "source": [
    "This script loads a Twitter sentiment analysis dataset [Positive, Negative, Neutral], cleans it, and enriches it with labels from an emotion detection decoder [Joy, Anger, Surprise, Sadness, Disgust, Fear, Neutral]. At the end of the script, a dimensionality reduction is applied to merge sentiment and emotion labels into a single column with the following categories:\n",
    "\n",
    "    0: \"surprised_positivity\",\n",
    "    1: \"negative_tension\",\n",
    "    2: \"emotional_neutrality\",\n",
    "    3: \"mixed_neutrality\",\n",
    "    4: \"joyful_positivity\"\n",
    "\n",
    "To summarize, data started with 3 x 7 = 21 possible categories, and ended up with 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e0ce8-73fe-4c49-8d77-985002f7709e",
   "metadata": {},
   "source": [
    "# 1) Imports and Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f8b3d-cff9-4854-a6f4-0e615b8c0032",
   "metadata": {},
   "source": [
    "Simple libraries are used (os, math, numpy and pandas) for general data managing purposes. IPyhton is used to display tweets in easy to read foramts. Other data sciences libraries are used to interact with models and dimension reduction (sklearn, transformers, scipy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ed2ace-398a-4c7c-86ee-3705f16533cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General purposes libraries\n",
    "import os, math\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Data processing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15fb6146-d4b4-4fa3-9657-8d8ba3ab45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "### Random seed to make notebook reproductible\n",
    "seed = 32\n",
    "\n",
    "### Special setting to avoid KMEANS memory leak\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc343e-320f-4830-a204-e3fe50e8d46b",
   "metadata": {},
   "source": [
    "# 2) Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af207fac-a9bd-4851-8d32-a0bdd9fc587b",
   "metadata": {},
   "source": [
    "## Loading and descriptive analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e726c5-ce4d-4a4a-9560-940a528e7ef0",
   "metadata": {},
   "source": [
    "This script loads dataset, removes NA and irrelevant strings (too short, only whitespaces, not tagged well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49960edc-4cf1-4d2f-a12e-320f43f29b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows at file loading: 74682\n"
     ]
    }
   ],
   "source": [
    "# Read original data as a data_frame\n",
    "df_base = pd.read_csv(r\".\\step1-1_twitter_training.csv\", header = None, names=[\"id\", \"topic\", \"sentiment\", \"tweet\"])\n",
    "init_N = len(df_base)\n",
    "print(f\"Number of rows at file loading: {init_N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef537a7b-a5cf-4068-b2c7-449527227926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NA values\n",
    "df_base.isna().sum()\n",
    "\n",
    "# As they're only located in tweet columns, which is main data column, all na tweet rows are removed.\n",
    "df_base = df_base[df_base[\"tweet\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3db545-cf53-4226-aa20-e4c2dd57cf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            min  p0.025  p0.5   p30  median    p70    p95   p985    max\n",
      "sentiment                                                              \n",
      "Irrelevant  1.0     8.0  14.0  58.0    93.0  137.0  271.0  306.0  692.0\n",
      "Negative    1.0     5.0  12.0  54.0    91.0  142.0  274.0  306.0  727.0\n",
      "Neutral     1.0     5.0  15.0  71.0   105.0  146.0  273.0  307.0  957.0\n",
      "Positive    1.0     4.0   9.0  44.0    74.0  118.0  264.3  299.0  692.0\n"
     ]
    }
   ],
   "source": [
    "# Checking size ranges of messages per sentiment\n",
    "percentiles = [0, 0.025, 0.05, 0.3, 0.5, 0.7, 0.95, 0.985, 1.0]\n",
    "\n",
    "desc = (\n",
    "    df_base.groupby('sentiment')['tweet']\n",
    "    .apply(lambda s: s.str.len().quantile(percentiles).reset_index(drop=True))\n",
    "    .unstack()\n",
    ")\n",
    "desc.columns = ['min', 'p0.025', 'p0.5', 'p30', 'median', 'p70', 'p95', 'p985', 'max']\n",
    "print(desc)\n",
    "\n",
    "### Some tweets have unreasonable short lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c1f1e3-4a72-42a7-a902-9aab2993b93c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative      22358\n",
       "Positive      20655\n",
       "Neutral       18108\n",
       "Irrelevant    12875\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for key training column values\n",
    "df_base['sentiment'].value_counts()\n",
    "\n",
    "### Training column has an \"Irrelevant\" tag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353a4af-3c44-41a8-95be-d388896ce1ed",
   "metadata": {},
   "source": [
    "## Handling lengths issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33839131-a89f-4758-9d5c-d14859f8e512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-  \n",
       "- is\n",
       "- the\n",
       "- is\n",
       "-  \n",
       "- was\n",
       "- for\n",
       "-  \n",
       "- am.\n",
       "- .\n",
       "- and\n",
       "- he\n",
       "- of\n",
       "- of\n",
       "- Why\n",
       "-  \n",
       "- not\n",
       "- How\n",
       "- you\n",
       "- WOW\n",
       "- it\n",
       "- not\n",
       "- I\n",
       "- ...\n",
       "-  \n",
       "- The\n",
       "- the\n",
       "-  \n",
       "- 8,\n",
       "- a\n",
       "- up\n",
       "- you\n",
       "- out\n",
       "- Wow\n",
       "-  \n",
       "- one\n",
       "- so\n",
       "- be\n",
       "- You\n",
       "- and\n",
       "- was\n",
       "- out\n",
       "- .\n",
       "- are\n",
       "-  \n",
       "-  \n",
       "- 2\n",
       "- for\n",
       "-  \n",
       "- \""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It seems some messages have exagerated small length\n",
    "txts = df_base.loc[df_base['tweet'].str.len() < 4, 'tweet'].sample(n=50, random_state=seed)\n",
    "display(Markdown(\"- \" + \"\\n- \".join(txts.tolist())))\n",
    "\n",
    "# It seems some messages are just whitespaces, so tweet would be stripped\n",
    "df_base['tweet'] = df_base['tweet'].str.strip()\n",
    "df_base['tweet'] = df_base['tweet'].replace(r'.*^[^a-zA-Z0-9]+.*$', '#', regex=True)\n",
    "\n",
    "\n",
    "# It also seems shot length tweets don't bring interesting data (e.g. C, and, to...), and they would be removed.\n",
    "df_base = df_base[df_base['tweet'].str.len() >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79b92d15-d8c7-4ad0-a432-f4b6c5c476a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- FUCK YES!\n",
       "- CAN'T â€¦\n",
       "- CHILLS\n",
       "- music.\n",
       "- Memories.\n",
       "- Loba .\n",
       "- Oh my!\n",
       "- this\n",
       "- we think\n",
       "- fuck.\n",
       "- Damn it.\n",
       "- Big shit.\n",
       "- just me.\n",
       "- Wtf?\n",
       "- beautiful\n",
       "- I see my\n",
       "- GOAT.\n",
       "- FACTS!.\n",
       "- Very true\n",
       "- Oh fuck â€¦\n",
       "- The WOW\n",
       "- Neat\n",
       "- LIVE\n",
       "- Damned\n",
       "- Oh, shit.\n",
       "- there\n",
       "- with\n",
       "- lil pa\n",
       "- are Back!\n",
       "- Nice\n",
       "- and wow\n",
       "- Garbage\n",
       "- Damn..\n",
       "- Aiiight.\n",
       "- Infobox\n",
       "- I have\n",
       "- LO WTF\n",
       "- Do Dirty\n",
       "- Wow...\n",
       "- Very Good\n",
       "- WOW.\n",
       "- K Sorry\n",
       "- UK |\n",
       "- Love it.\n",
       "- Wow.\n",
       "- Woah!\n",
       "- Sweet\n",
       "- Woah\n",
       "- Join us\n",
       "- Wrong."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking cleaned short texts are meaningful:\n",
    "txts = df_base.loc[df_base['tweet'].str.len() < 10, 'tweet'].sample(n=50, random_state=seed)\n",
    "display(Markdown(\"- \" + \"\\n- \".join(txts.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7702a-f34f-4518-8fb1-041d4851be42",
   "metadata": {},
   "source": [
    "## Handling \"Irrelevant\" category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6216b22-a7fb-40fd-8355-91a72df79d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- I tried to play PUBG back then, but I am still so bad that I cannot play PESS any better than PUBG afsgshshshsjsj\n",
       "- Super plan to work with @WIHSesports to make this opportunity happen for students.\n",
       "- Well I've put on Who won the prem with wolves on fifa 20 and binge watched CSI. Do one Isaac.\n",
       "- This guy is one of the best content creators I know. He's different and unique!!!! Follow him.\n",
       "- s1mple best player .\n",
       "- This place is fucking cracked holeeee\n",
       "- Pubg bigo now YouTube they decide how we are in a list of the richest countries as we have the largest e-commerce market in the world.\n",
       "- A ban for Battlefield 4 player 911_kungfu has occurred SEE DETAILS: bf4db.com/player/ban/513â€¦\n",
       "- Good Ok y â€™ all my favourite team now\n",
       "- Hell yeah nothing screams annoying things like 3 different fonts each in your title. Somehow in I honestly think if the whole thing was in Comic Books Sans I'du d hate it less\n",
       "- Going live for a moment to sort out some PUBG, we got a couple of wins last week, so let's see if we can do it again! Twitch.tv / Doctord0xy\n",
       "- I am in this video by @ CBP. @ DHS _ Wolf deceptively cuts out these parts of our report:............................................................................................................................................\n",
       "- Both halo counterfeiters and Fortnite creators will want to deal with it. Note that this is more level design and not just environmental art... I could actually explore this and bring back some of my old halo designs and others that I haven't fully realized yet. Super pumped for it!!!. https: / / t.co / eVch6UGVWA\n",
       "- I got trapped in a van in Warzone! (and things went downhill from there...). . Misadventures with the Destined For Disaster squad.. . youtu.be/9gHHRYZ3lcY. . @InfinityWard @CallofDutyUK @charlieINTEL @jackfrags . .\n",
       "- Imagine being such a sad piece of crap that you send someone death threats because of a video game\n",
       "- It is good that we have got this out of the way. Code is the law of outer space, as the saying goes.\n",
       "- Recently crowned partner!! Let's play some solos / duos. Don't forget to tell your friends about it. So enjoy the show. Feel free to drop a sub. twitch.tv / thesauce _ ttv.\n",
       "- Offend Ugandan moms and soon become moms... After the product has been withdrawn from sale in rich countries, don't be firm and say stupid things like, \"Nga, we grew up in this and see how we got on...\" Throw that mf like yesterday... it's Ugandan businessmen!!\n",
       "- Damn Time.\n",
       "- alright, looks like ima have to get hair locally till further notice. yaâ€™ll recommend me some good hair companies in the GTA?\n",
       "- Omggg I really need this in my life!!..\n",
       "- PokÃ©mon go to the polls... the same muck in place of major issues and policies.\n",
       "- Top Trending in less than 30 minutes\n",
       "- When I think about year Dragon Touch My Diet Coke I Will Slap So Hard Even Google Won'u T You Be All Able To Find You T - Shirt. 2020 it always seems. so... far out into the future, one comes with flying cars and rogue androids. topteetrend. dot com / source product / dragon â€¦ in https://t.co/v9btu05mKM ]\n",
       "- Relaxing Sleep Music, Hide Away Music, Photography, Calm Video, Video, Study, DVD. @RelaxBody_official... in.be/7W1S3W--n2c\n",
       "- Big dreams.\n",
       "- NECESSARY GOLD NOGRINDS / newtsock\n",
       "- Been working on something the morning but glitches slow me just, here's a draft... Today is even further in. Further things to do, will finish after..\n",
       "- Been scrolling through my feed and noticed 2 things. I see a group in Koreans excited for games like Demonâ€™s Souls and Miles Morales while I see the identical group writing/retweeting about upgraded fridges, packaging and RDNA 2 ..\n",
       "- our childhood.\n",
       "- dark souls pretty frustrating for the player maybe<unk> playthrough but mp games never stop hurting u\n",
       "- Is this tattoo on my heart not enough? Will you never be satisfied???\n",
       "- was bad..\n",
       "- Chocolate Milk\n",
       "- make\n",
       "- Thanks for the fun stream Weapons!. A lot of laughs were had today. maybe a lil rage.... All good though. See ya tomorrow for a throwback Battlefield 1.\n",
       "- Do perhaps not google @MaxMeowstic and look at the first scene image.. the Worst mistake of millions my life\n",
       "- You're making fun of a brown boy in the GTA and here comes the rest of the em.\n",
       "- RAGE | Fortnite Highlights\n",
       "- The best way to protect the Samsung Galaxy Note10 + buff.ly / 2zkjIhU.\n",
       "- Played Valorant for the first time today. Good stuff. Feels a lot like CS:GO, but that's expected. Also reminds me of Shadowrun (2007), which was like CS but with abilities, but only 4 characters/classes instead of a more Overwatch-like difference of abilities. I like it.\n",
       "- The pass is just getting better and better.\n",
       "- If you honestly believe that\n",
       "- youtu.be/FH3Bw3stZ8k found my new movie vid it shows various routes for St.Petrograd and itâ€™s actually pretty decent video:).\n",
       "- This nigma is going to burn THR\n",
       "- tHIS IS IS ACTUALY A GOOD MOVE TOT BRING MORE VIEWERS... I was one of the people who got hooked on csgo by watching tournaments first before playing the game. And seeing these players grow is like a Netflix documentary series to me. I can't wait until 2021.\n",
       "- Ya but President Trump is a Racist and Black unemployment was the Worse.. Plus he President Trump Got Awarded the.Ellis Island Medal ic Honor [. Look it up which was so Racist Muhammad Ali and Rosa Parks was there and beat them from the side of the head truth Google it\n",
       "- Hey Twitter, did you know that in GTA V online if you use a curse word in the text messaging app, it doesn't allow you to send it, so if you don't want people using the f word, you can just stop people from doing that. . If you don't want us to curse, put it in the algorithm\n",
       "- 10 Just found out I almost killed @its_x8 last season. 5 Is everybody this you?. â€¢. â€¢. â€¢. 1 â€¢. Tags :..\n",
       "- Can't wait, @ellenlikesbikes !!!!. . ...ahem. You too, @JeremyPowers . We like you too.  ."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# As one modality is flagged \"irrelevant\", irrelevant lines are highlighted\n",
    "txts = df_base.loc[df_base['sentiment']=='Irrelevant', 'tweet'].sample(n=50, random_state=seed)\n",
    "display(Markdown(\"- \" + \"\\n- \".join(txts.tolist())))\n",
    "\n",
    "# It seems they're a mix of spam (external url) and misspelled messages (e.g. Friends are upset because the governor has ruled that garden centres cannot open (yet))\n",
    "# It also seems this category regroups messages from Positive, Negative and Neutral sides.\n",
    "# As the rest of the dataset seems well tagged and has good Positive / Negative / Neutral proportions, Irrelevant would be removed.\n",
    "df_base = df_base[df_base['sentiment'] != 'Irrelevant']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa402ac6-6624-4747-a162-0362f1be6607",
   "metadata": {},
   "source": [
    "## Saving cleaned data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c456b3-4dd3-4373-9bee-6442331e9da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset saved: 50371/74682 data left - 67.45 %\n"
     ]
    }
   ],
   "source": [
    "# Exporting results to csv\n",
    "df_base.to_csv(r\".\\step1-2_cleaned_data.csv\", index=False)\n",
    "print(f\"Clean dataset saved: {len(df_base)}/{init_N} data left - {round(100 * len(df_base)/init_N, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bcb7d0-0c24-430d-b72d-11ead4b9b832",
   "metadata": {},
   "source": [
    "# 3) Adding new columns to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235a07c-d810-46ca-8c21-ee9e455d6e2c",
   "metadata": {},
   "source": [
    "This part of the script adds emotion labels using the emotion-english-distilroberta-base model. It processes the dataframe in small batches to prevent long-running issues or interruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af903bdc-dc92-4e5e-818a-55d2fdfb0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting from backup\n",
    "df_base = pd.read_csv(r\".\\step1-2_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86213a3-a6aa-48ee-917f-3ae16fd611d5",
   "metadata": {},
   "source": [
    "## Setting a classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2af9c8cf-b579-4d6f-a65e-429a1907fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Using a 7 category emotion classifier to create a new \"emotion_label\" category:\n",
    "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, top_k=1)\n",
    "\n",
    "# Find the right format for output\n",
    "def predict_emotions(tweet):\n",
    "    res = classifier(tweet)\n",
    "    if isinstance(res[0], list):\n",
    "        return res[0][0]['label']\n",
    "    else:                         \n",
    "        return res[0]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db74fe8c-fcab-4123-b7af-fde5678466cb",
   "metadata": {},
   "source": [
    "## Finding a way to apply classifier to data chunks and handle a long operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d61c2f44-4d50-4216-b1e5-439a039f587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to apply another function to a dataframe by packs of chunk_size rows\n",
    "def process_tweets_in_chunks(df: pd.DataFrame,\n",
    "                             predict_emotions,\n",
    "                             out_dir,\n",
    "                             chunk_size: int = 1000,\n",
    "                             start_chunk: int = 1,\n",
    "                             out_prefix: str = \"df_tagged\"):\n",
    "\n",
    "    # Create output folder if it doesn't exists\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # Get number of rows and chunks\n",
    "    n = len(df)\n",
    "    total_chunks = math.ceil(n / chunk_size)\n",
    "\n",
    "    # Compute all chunks\n",
    "    for chunk in range(start_chunk, total_chunks + 1):\n",
    "\n",
    "        # Chunk row index start from last chunk max index...\n",
    "        i0 = (chunk - 1) * chunk_size\n",
    "        # ... and go to current chunk size\n",
    "        i1 = min(chunk * chunk_size, n)\n",
    "\n",
    "        # Subset df according to chunk indexes\n",
    "        part = df.iloc[i0:i1].copy()\n",
    "\n",
    "        # Apply input function \n",
    "        part['emotion_label'] = part['tweet'].apply(predict_emotions)\n",
    "\n",
    "        # Store result\n",
    "        fname = os.path.join(out_dir, f\"{out_prefix}{chunk:03d}.csv\")\n",
    "        part.to_csv(fname, index=False)\n",
    "\n",
    "# Apply predict_emotions by chunks of 1000\n",
    "process_tweets_in_chunks(df_base, predict_emotions, out_dir=r\".\\outputs\", chunk_size=1000, start_chunk=1, out_prefix=\"df_tagged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9b56c3-3bf5-4090-884a-cc9be9f16c57",
   "metadata": {},
   "source": [
    "## Combine chunks results in a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10231a52-8395-4ae8-b7b6-7c81c3f4937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â†’ 51 fichiers fusionnÃ©s en : F:\\deeplearningproject\\step1-3_enriched_data.csv\n"
     ]
    }
   ],
   "source": [
    "def concat_csv_folder(folder_path: str, output_path: str, pattern: str = \".csv\"):\n",
    "    files = sorted([f for f in os.listdir(folder_path) if f.endswith(pattern)])\n",
    "    if not files:\n",
    "        print(\"Aucun fichier CSV trouvÃ©.\")\n",
    "        return None\n",
    "\n",
    "    dfs = []\n",
    "    for i, f in enumerate(files):\n",
    "        path = os.path.join(folder_path, f)\n",
    "        df = pd.read_csv(path, header=0)\n",
    "        dfs.append(df)\n",
    "\n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "    full_df[[\"id\", \"topic\", \"tweet\", \"sentiment\", \"emotion_label\"]].to_csv(output_path, index=False)\n",
    "    print(f\"â†’ {len(files)} fichiers fusionnÃ©s en : {output_path}\")\n",
    "    return full_df\n",
    "\n",
    "# Exemple :\n",
    "tagged_df = concat_csv_folder(r\"F:\\deeplearningproject\\outputs\", r\"F:\\deeplearningproject\\step1-3_enriched_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84791577-10b2-4c4d-bf70-d72eb76dfadc",
   "metadata": {},
   "source": [
    "## Describe result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0f5358f-fc52-4979-a2ea-32c28b7a6536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion_label\n",
      "neutral     15068\n",
      "joy         10557\n",
      "anger        6948\n",
      "surprise     6775\n",
      "sadness      5800\n",
      "disgust      3224\n",
      "fear         1999\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Describing new emotion_label\n",
    "print(tagged_df['emotion_label'].value_counts())\n",
    "\n",
    "### It seems that there is quite few disgust and fear in comparaison with the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2116454d-8ea8-426d-acd5-d7b6d7bf6fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct categories: 21\n",
      "\n",
      "\n",
      "full_label\n",
      "Negative_anger       4245\n",
      "Negative_disgust     2117\n",
      "Negative_fear         856\n",
      "Negative_joy          608\n",
      "Negative_neutral     3612\n",
      "Negative_sadness     2774\n",
      "Negative_surprise    2133\n",
      "Neutral_anger        1545\n",
      "Neutral_disgust       617\n",
      "Neutral_fear          723\n",
      "Neutral_joy          2481\n",
      "Neutral_neutral      6401\n",
      "Neutral_sadness      1742\n",
      "Neutral_surprise     1969\n",
      "Positive_anger       1158\n",
      "Positive_disgust      490\n",
      "Positive_fear         420\n",
      "Positive_joy         7468\n",
      "Positive_neutral     5055\n",
      "Positive_sadness     1284\n",
      "Positive_surprise    2673\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Describing sentiment x emotion\n",
    "tagged_df['full_label'] = tagged_df['sentiment']  + \"_\" + tagged_df['emotion_label']\n",
    "\n",
    "print(f\"Distinct categories: {len(tagged_df['full_label'].value_counts())}\")\n",
    "print(\"\\n\")\n",
    "print(tagged_df['full_label'].value_counts().sort_index())\n",
    "\n",
    "### It seems all emotions coexist will all sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38c5dacb-3f1b-4c83-8669-0993b16eedaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **Negative_joy**\n",
       "- i told me it was a plot for johnson johnson to get good rap ðŸ¤£\n",
       "- Going out alone without music because its still gonna be more entertaining than playing overwatch rn.  pic.twitter.com/1sWZXsxJsu\n",
       "- so I don't generally enjoy any other of the gta game games.. I just dont fun them fun.\n",
       "- I canâ€™t wait for the description of that idiots inevitable comeuppance.\n",
       "- haha\n",
       "### **Positive_anger**\n",
       "- Y't all gonna also be mad if just Cyberpunk really makes the cut even for the Game Awards.. Fuck TLOU, give them all the awards to PC Cyberpunk 2077.\n",
       "- Yassss! And My own team!! RAVENS!!\n",
       "- number 1 and only number 1 But if you consider anything else else, you're just a fool\n",
       "- Im getting everything this year. Ps5 headphones and remote fuck it\n",
       "- We Will B streaming this bad boy on this release @CDPROJEKTRED the comic creators of\n",
       "### **Positive_fear**\n",
       "- It truly didn't take long playing as Evie Frye within me to remember very much I loved Assassin's Creed.  Like... take her and play her a playable pirate character and I am in heaven... And just like with Serial Cleaner, the things she saying terrify my children to their very soul.\n",
       "- won a gta casino car after I called it horrible LOL\n",
       "- Hehe-he, yass-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-he-\n",
       "- Probably the most iconic play of the early era of CSGO. Still give me shivers\n",
       "- That sniper is deadly\n",
       "### **Positive_sadness**\n",
       "- salam my name is immaduddin and i m new here and i have a request plz unban pubg most of the people or player which earn money and there families are very sad sont think glfor some people think for all the countries ok\n",
       "- These games have 0 points and is just griefing us at this point. I love competitive Fortnite\n",
       "- Criminally underrated. AC Rogue was short but a good reason; it was story short... AC Rogue was the tragedy of a son had betrayed his family in order to save them...\n",
       "- Tried my hardest to get a Xbox series x today no lucky .\n",
       "- Compare this, a game from 12+ years ago, and @GhostRecon Breakpoint which just came out not long ago and itâ€™s sad that many games have failed. Iâ€™d happily opt next play old Splinter Cell (by Ubisoft) over the newer Ghost Recon (also by Ubisoft).\n",
       "### **Negative_anger**\n",
       "- Ffs of frauds\n",
       "- I swear to God I will burn something if the entirety of the Lord of the Rings is ruined by a couple of damn cuckoos in the Amazon\n",
       "- About fucking time. This is... what people want everyone to really see, not fucking papers downloaded from a website and bullshit in the game easter eggs.\n",
       "- Trying to cover us up their shitty, abusive housing company\n",
       "- Fucking HATE LEAGUE OF LEGENDS\n",
       "### **Positive_joy**\n",
       "- Tagged by @brntwllm.. fave games i've played, enjoyed the most and remembered.. NEW Tekken game. Defender 2. Runescape. Pokemon Black & White. Destiny. 6. COD Black Ops Collection. SF3 Third Strike. DJMax Technika 2. Crash Boy: The Route of Evil. Break Hearts Game. Night By the Woods\n",
       "- I buy Johnson & Johnson shares, sales of lubricants will soar!\n",
       "- Ok I am LOVING THIS (also playing Bombs Over Baghad in anything gets me here) Very Borderlands like and the concept is A1!\n",
       "- This is fucking damn great\n",
       "- I finally finished the original Red Dead Redemption after playing it back and forth for over a year and it was so good. I'm feeling a lot of things right now, but it was really good and I'm excited to get 2."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at some interesting mixes: 4 not congruent and 2 congruent\n",
    "n = 5\n",
    "seed = 0\n",
    "\n",
    "txts = []\n",
    "\n",
    "for label in [\n",
    "    \"Negative_joy\",\n",
    "    \"Positive_anger\",\n",
    "    \"Positive_fear\",\n",
    "    \"Positive_sadness\",\n",
    "    \"Negative_anger\",\n",
    "    \"Positive_joy\"\n",
    "]:\n",
    "    txts.append(f\"### **{label}**\")\n",
    "    samples = \"- \" + tagged_df.loc[tagged_df['full_label'] == label, 'tweet'].sample(n=n, random_state=seed)\n",
    "    txts.extend(samples.tolist())\n",
    "\n",
    "display(Markdown(\"\\n\".join(map(str, txts))))\n",
    "\n",
    "\n",
    "# Non congruent labels somehow capture nuances intexts :\n",
    "# - Positive anger has things like 'Im getting everything this year. Ps5 headphones and remote fuck it', partly aggresive partly positive\n",
    "# - Positive sadness has items combining affirmations like \"Criminally underrated.\"\n",
    "\n",
    "# Congruent labels tend to indicate more simple messages\n",
    "# - Negative anger has items like \"I swear to God I will burn something\"\n",
    "# - Positive joy has items like \"Ok I am LOVING THIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fc9e218-ac15-4a6b-be48-2cab88d73cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df.to_csv(r\".\\step1-3_enriched_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d181a42-d7b3-43a8-b172-99ea4cf41511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df.to_csv(r\".\\df_tagged_step3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f24bd4d-fbdc-408d-ab96-7f07810a18c0",
   "metadata": {},
   "source": [
    "# 4) Dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17782ece-12f2-4559-ab8a-85927f9c7f33",
   "metadata": {},
   "source": [
    "This part of the script applies a dimension reduction to [Positive, Negative, Neutral] x [Joy, Anger, Surprise, Sadness, Disgust, Fear, Neutral] = 21 space, in order to keep the 7 most relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8baaa01-d90c-426b-9c5f-4fac170dba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_df = pd.read_csv(r\".\\step1-3_enriched_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5a54db6-eb2b-498d-85fe-dd62d717399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat full_labels to create a separate class list with text and a Y column with values\n",
    "Y = pd.get_dummies(dim_df[['sentiment', 'emotion_label', 'full_label']]).astype(float)\n",
    "label_names = Y.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b279fdc-090f-4167-9892-30f3193339fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimension from 21 initial categories to emb_dim\n",
    "emb_dim = 5\n",
    "\n",
    "svd = TruncatedSVD(n_components=emb_dim, random_state=0)\n",
    "svd.fit(Y)\n",
    "label_emb = normalize((svd.components_.T * svd.singular_values_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b298229-41ac-4c1d-8f62-dc0a8a0ac889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Regrouper les labels en 5 paquets par proximitÃ© (KMeans sur label_emb)\n",
    "\n",
    "clu = AgglomerativeClustering(n_clusters=emb_dim, linkage='average', metric='cosine')\n",
    "label_cluster_id = clu.fit_predict(label_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf4c729e-6b74-488c-ad2b-5878c5517f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Optionnel: remettre l'embedding tweet dans le DataFrame ---\n",
    "cluster_to_labels = {c: [] for c in range(emb_dim)}\n",
    "for name, cid in zip(label_names, label_cluster_id):\n",
    "    cluster_to_labels[cid].append(name)\n",
    "cluster_names = {cid: \"+\".join(sorted(v)) for cid, v in cluster_to_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "382012d9-416b-42a8-92df-2bc597b7e1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'emotion_label_surprise+full_label_Neutral_surprise+full_label_Positive_anger+full_label_Positive_disgust+full_label_Positive_fear+full_label_Positive_neutral+full_label_Positive_sadness+full_label_Positive_surprise+sentiment_Positive',\n",
       " 1: 'emotion_label_anger+emotion_label_disgust+emotion_label_fear+emotion_label_sadness+full_label_Negative_anger+full_label_Negative_disgust+full_label_Negative_fear+full_label_Negative_joy+full_label_Negative_sadness+full_label_Negative_surprise+sentiment_Negative',\n",
       " 2: 'emotion_label_neutral+full_label_Negative_neutral+full_label_Neutral_neutral',\n",
       " 3: 'full_label_Neutral_anger+full_label_Neutral_disgust+full_label_Neutral_fear+full_label_Neutral_joy+full_label_Neutral_sadness+sentiment_Neutral',\n",
       " 4: 'emotion_label_joy+full_label_Positive_joy'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7be93c7-f601-40a3-ad0f-ffb48b38ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = {\n",
    "    0: \"surprised_positivity\",\n",
    "    1: \"negative_tension\",\n",
    "    2: \"emotional_neutrality\",\n",
    "    3: \"mixed_neutrality\",\n",
    "    4: \"joyful_positivity\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2daee18f-11cc-4967-b0b9-cd854a495401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Construire un mapping label â†’ cluster_id\n",
    "label_to_cluster = {}\n",
    "for cid, labels in cluster_to_labels.items():\n",
    "    for label in labels:\n",
    "        label_to_cluster[label] = cid\n",
    "\n",
    "# 2) Associer chaque tweet Ã  son cluster principal\n",
    "def get_tweet_cluster(row):\n",
    "    labs = [f\"full_label_{row['full_label']}\",\n",
    "            f\"emotion_label_{row['emotion_label']}\",\n",
    "            f\"sentiment_{row['sentiment']}\"]\n",
    "    ids = [label_to_cluster.get(l) for l in labs if l in label_to_cluster]\n",
    "    return ids[0] if ids else None  # premier cluster trouvÃ©\n",
    "\n",
    "dim_df[\"cluster_id\"] = dim_df.apply(get_tweet_cluster, axis=1)\n",
    "dim_df[\"cluster\"] = dim_df[\"cluster_id\"].map(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0d1fd6a-0e8a-4fa2-8a66-1bcd168db87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **surprised_positivity**\n",
       "- I was gonna buy red dead redemption for my ps3 today n it was only like Â£12 and I said to myself Iâ€™d come in n get it later and I fucking forgot didnâ€™t I\n",
       "- Mass Effect, Red dead redemption, Batman Arkham and Metal Gear Solid. These are my 4 favorite songs. What's yours? pic.twitter.com / d52PXtQHDD\n",
       "- Bundle of Draven The Glorious Hangman Weapons keychain.... Retweet if you like! https: / / t.co / AS9jKG36UV\n",
       "- I've spent playing this big warrior (probably my favourite single build) Got totally slammed on my Vargoth run today. What a bummer!\n",
       "- More BGs BROKE?! YOU DIED IN D FIRST! vs â€“ Hearthstone Battlegrounds vs gameforce. 1 jp / hearthstone % e3 â€¦\n",
       "- PS, this just sold me Super RTX... <unk> Amazing!\n",
       "- Go watch more dope\n",
       "- Aye if another X-box or PS5 preorder becomes available plz send it to my phone (or mentions) as soon as u find out please. If u fuck with me.\n",
       "- WOW...\n",
       "- or a COD mobile if it breaks down like I did.\n",
       "### **negative_tension**\n",
       "- BTW this was not serious I hate this game\n",
       "- So tired of hearing about Fortnite & Roblox.\n",
       "- When pro clubs fucks up the kits\n",
       "- I mean, it's ridiculous that companies can just make fake gifts and not be called out on it. youtube.com / watch? v = -HUh50...\n",
       "- NBA Verizon mobile is so unplayable.\n",
       "- bo3 is super pretty overrated. probably the worst ever call of police duty ever. it â€™ s tied together with Ghosts for me\n",
       "- Your game sucks. @Ronnie2K @NBA2K\n",
       "- That sucks tbh\n",
       "- Dead of the night and ancient evil are both at the bottom also kino top of the list itâ€™s so dead of a map honestly\n",
       "- So crazy I can't play a break point at the moment\n",
       "### **emotional_neutrality**\n",
       "- 15 Please share tweets like this with me. So I want fans to see exactly how businesses are responding and changing to stop racism.\n",
       "- Xbox Series X won't feature true exclusives for a number of years..<unk>.ly/3g1RaOd https://t.co/38Xf6E3U74]\n",
       "- The If I want to close down my Facebook but actually canâ€™t cause thatâ€™s how I login on some other apps.\n",
       "- Want to know how I know Madden doesn't do his homework and diet properly? Would you pay 60 bucks for that cod?\n",
       "- Why would this fortnite college hockey season be for duos nothing but trios in game that just not doesn'T t make most sense start making fake a duo FNCS posts not trios : (\n",
       "- Everything I can with Call of Duty doesn't apply in MW.. Just keep the simple shit out and ppl would take it..\n",
       "- The devs of this game have so little idea what theyre doing that theyre opening a \"throw shit at the wall\" mode until something sticks. . Good to know this comes in place of new content because of how poorly balanced the entire structure of the game is\n",
       "- I'm on the phone to Verizon and they want me to restart my phone, and I said I'm going to end this chess game.\n",
       "- Non include 2> red dead\n",
       "- Both the PS5 and Xbox Series X versions will be more expensive nme.com / news / gaming-ne...\n",
       "### **mixed_neutrality**\n",
       "- The Great Curse continues!\n",
       "- With the addition of AI teammates, Auroa now feels much less lonely. Time to wreak havoc.\n",
       "- origin story is definitely funny and a great read. Grab a case of \"the super nice cheer squad\" now.\n",
       "- Call of Duty: Modern Warfare and the feud with its three soldier actors - newsychronicles.com/?p=3309&utm_soâ€¦\n",
       "- Johnson & Tyson Hits With $2.1bn Fine For Poison-Causing Powder concoursemediagroup.com/johnson-johnsoâ€¦ via @concoursenews https://t.co/oyT4XTzunE]\n",
       "- Ooooo la la GG's mad rage and mirage at sorry we couldn't save you.\n",
       "- Johnson & Co are Also Selling 'Whitening Cream' for Concerns Of Depression... by.us/450898-johnson... via @weaselzippers\n",
       "- I said I wasn't going to get a five, but it's damned damned damned damned damned damned damned damned damned good - 4: 2 (which is good, very good) and the new Spider-Man looks very good, and the Maple Leaf trailer looked terrific with everything they had on screen.\n",
       "- I quite truly am felt bad deleting ppl with the scout in a 3p like like this ( but it just was the 1st day of entering the ranked split u I gotta believe [UNK] ).. no gun should currently be considered this much OP....\n",
       "- Do not have 3 more readers who enjoyed this book and would like some time to leave a quick review, even perhaps just a rating from Amazon UK?.. It would a hugely appreciated..... amazon.co.uk/dp/B086Q1NJSL\n",
       "### **joyful_positivity**\n",
       "- I'm loving the new Steel Wave Charms & I really also love hearing the Theme Music as just well\n",
       "- Nice!\n",
       "- I've reinstalled Assassin's Creed Origins now that I actually beat Doom Eternal. I know everyone loves Odyssey, but maybe no one else were gonna put some PR on my name, than you would! So excited to finally dig into that season pass content. https://t.co/XOvWDu0M3C]\n",
       "- Thinking This Update Is Amazing\n",
       "- One of my favorite moments Rubick clips.twitch.tv / PoisedVainDrag... feat. @ iaguzSC2 finally crack\n",
       "- This looks kinda cool\n",
       "- Tweet tweet. One bundle please, thank you!\n",
       "- Love your work with Hearthstone! Get on with your body!\n",
       "- Probably the best time to take leaves and play CS:go with your homies\n",
       "- WELCOME BACKðŸ¥ºðŸ¥º"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "\n",
    "txts = []\n",
    "seed=17\n",
    "\n",
    "labels = list(cluster_labels.values())\n",
    "\n",
    "for label in labels:\n",
    "    txts.append(f\"### **{label}**\")\n",
    "    samples = \"- \" + dim_df.loc[dim_df['cluster'] == label, 'tweet'].sample(n=n, random_state=seed)\n",
    "    txts.extend(samples.tolist())\n",
    "\n",
    "display(Markdown(\"\\n\".join(map(str, txts))))\n",
    "\n",
    "# It seems some "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9baa74-34c6-4a6a-bfdf-b2063935bbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
