{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6223c80-eaee-4835-9448-1b6fcfe9f6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment ready â€” cleaning validation dataset...\n",
      "ğŸ“‚ Validation rows loaded: 1001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "topic        0\n",
       "sentiment    0\n",
       "tweet        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ After cleaning short/empty tweets: 996/1001 rows kept (99.5%)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Example Irrelevant tweets:\n",
       "- Very interesting read! I agree more women should have careers in Cybersecurity! \n",
       "\n",
       "Are Women Better At Cybersecurity Than Men? What A Study Showed About Password Security And More bit.ly/3fDK96k #passwords #womenintech #Cyberintelligence #Cyberpunk2077 https://t.co/xiG31G5DfR\n",
       "- This is my 143rd twitter account, I keep getting suspended. Pelosi ruined my life, I should be able to have a voice. If you dont know me, just google \"SnaggleTooth Salon\"\n",
       "\n",
       "I gave her bush an Afro. I may release the video.\n",
       "\n",
       "RT & Please Follow, and I'm full of shit & begging again.\n",
       "- [Dirty-Gaming] GTA RP !  JJ on Tour, hat eine Villa < 3 twitch.tv/p0werflyyy\n",
       "- @Pinkwardlol so mad you lost that game of CSGO you banned me from your Twitch i'm weakkk\n",
       "- You mean real life crack epidemic?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš« Dropped 'Irrelevant' category to match training data (3 labels left).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Neutral      285\n",
       "Positive     275\n",
       "Negative     263\n",
       "Sentiment      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Example short but valid tweets:\n",
       "- Wow..\n",
       "- Kings ğŸ’¯ğŸ”¥\n",
       "- Aiiight ğŸ’ª\n",
       "- Damn\n",
       "- fuck..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Clean validation dataset saved to:\n",
      "C:\\Users\\Abraham\\Documents\\Dell\\DSTI\\19- Deep learning\\Project\\Datasets\\step1-2_cleaned_validation.csv\n",
      "âœ… Final size: 824 rows (82.32% retained)\n",
      "âœ… Sentiments: ['Sentiment', 'Neutral', 'Negative', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# STEP 1: Imports and Environment Setup\n",
    "#########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "\n",
    "print(\"âœ… Environment ready â€” cleaning validation dataset...\")\n",
    "#########################################################################\n",
    "# STEP 2: Load the Validation Dataset\n",
    "#########################################################################\n",
    "\n",
    "# Path to your validation CSV\n",
    "val_path = r\"C:\\Users\\Abraham\\Documents\\Dell\\DSTI\\19- Deep learning\\Project\\Datasets\\twitter_validation.csv\"\n",
    "\n",
    "# Load with column names consistent with training\n",
    "val_df = pd.read_csv(val_path, header=None, names=[\"id\", \"topic\", \"sentiment\", \"tweet\"])\n",
    "\n",
    "init_N = len(val_df)\n",
    "print(f\"ğŸ“‚ Validation rows loaded: {init_N}\")\n",
    "\n",
    "# Check for missing values\n",
    "display(val_df.isna().sum())\n",
    "\n",
    "#########################################################################\n",
    "# STEP 3: Remove Missing or Empty Tweets\n",
    "#########################################################################\n",
    "\n",
    "# Drop rows where tweet is missing\n",
    "val_df = val_df[val_df[\"tweet\"].notna()]\n",
    "\n",
    "# Strip whitespaces\n",
    "val_df[\"tweet\"] = val_df[\"tweet\"].astype(str).str.strip()\n",
    "\n",
    "# Replace lines that are just symbols or non-alphanumeric\n",
    "val_df[\"tweet\"] = val_df[\"tweet\"].replace(r'^[^a-zA-Z0-9]+$', '#', regex=True)\n",
    "\n",
    "# Drop tweets shorter than 4 characters\n",
    "val_df = val_df[val_df[\"tweet\"].str.len() >= 4]\n",
    "\n",
    "print(f\"ğŸ§¹ After cleaning short/empty tweets: {len(val_df)}/{init_N} rows kept \"\n",
    "      f\"({round(100*len(val_df)/init_N, 2)}%)\")\n",
    "\n",
    "#########################################################################\n",
    "# STEP 4: Handle â€œIrrelevantâ€ Category (Optional)\n",
    "#########################################################################\n",
    "\n",
    "# Inspect examples of Irrelevant if they exist\n",
    "if \"Irrelevant\" in val_df[\"sentiment\"].unique():\n",
    "    irrelevant_samples = val_df.loc[val_df[\"sentiment\"] == \"Irrelevant\", \"tweet\"].sample(\n",
    "        n=min(5, (val_df[\"sentiment\"] == \"Irrelevant\").sum()), random_state=seed\n",
    "    )\n",
    "    display(Markdown(\"### Example Irrelevant tweets:\\n- \" + \"\\n- \".join(irrelevant_samples.tolist())))\n",
    "    \n",
    "    # Drop the \"Irrelevant\" category for consistency with training clean file\n",
    "    val_df = val_df[val_df[\"sentiment\"] != \"Irrelevant\"]\n",
    "    print(\"ğŸš« Dropped 'Irrelevant' category to match training data (3 labels left).\")\n",
    "\n",
    "#########################################################################\n",
    "# STEP 5: Basic Sanity Checks\n",
    "#########################################################################\n",
    "\n",
    "# Check label distribution\n",
    "display(val_df[\"sentiment\"].value_counts())\n",
    "\n",
    "# Check short tweets again\n",
    "short_tweets = val_df[val_df[\"tweet\"].str.len() < 10].sample(n=min(5, len(val_df)), random_state=seed)\n",
    "display(Markdown(\"### Example short but valid tweets:\\n- \" + \"\\n- \".join(short_tweets[\"tweet\"].tolist())))\n",
    "\n",
    "#########################################################################\n",
    "# STEP 6: Save Cleaned Validation File\n",
    "#########################################################################\n",
    "\n",
    "output_path = val_path.replace(\"twitter_validation.csv\", \"step1-2_cleaned_validation.csv\")\n",
    "val_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"ğŸ’¾ Clean validation dataset saved to:\\n{output_path}\")\n",
    "print(f\"âœ… Final size: {len(val_df)} rows ({round(100*len(val_df)/init_N, 2)}% retained)\")\n",
    "print(f\"âœ… Sentiments: {val_df['sentiment'].unique().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2dbfbb-364f-4517-a411-3f480fee2232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
